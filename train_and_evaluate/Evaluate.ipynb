{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UlrnFeFhSO_B"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_dataset_names = [\"ISEAR\", \"DR\", \"Dreaddit\", \"SDCNL\", \"DepSeverity\"]\n",
        "data_path = \"/home/elicer/Tiny-Mental-LLM/Mental_Emotion_Dataset/final_merged_dataset/test\"\n",
        "if(data_path == \"\"):\n",
        "  raise Exception(\"Path for dataset not found\")\n",
        "\n",
        "token_path = \"Qwen/Qwen2-0.5B\"\n",
        "model_path = \"/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Output/csidibn1-Qwen-Qwen2-0.5B/checkpoint-3880\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "w1IZG2KLSDCv"
      },
      "outputs": [],
      "source": [
        "def _get_text_label_from_path(path):\n",
        "    # Assuming that the dataset file is csv and contains `text` & `label` columns\n",
        "    texts = []\n",
        "    labels = []\n",
        "    labels_set = set()\n",
        "    with open(path, \"r\", encoding = \"utf-8\") as test_file:\n",
        "        reader = csv.reader(test_file)\n",
        "        text_id = 0\n",
        "        label_id = 1\n",
        "        for id, _row in enumerate(reader):\n",
        "            if(id == 0 or len(_row) < 2):\n",
        "                continue\n",
        "            else:\n",
        "                texts.append(_row[text_id])\n",
        "                labels.append(label2id[_row[label_id]])\n",
        "                labels_set.add(_row[label_id])\n",
        "        test_file.close()\n",
        "    assert (len(texts) == len(labels)), \"Number of text {} is different from number of labels {}\".format(len(texts), len(labels))\n",
        "    return texts[:10], labels[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dmhczw1SSAoa"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(preds, labels):\n",
        "    accuracy_metric = evaluate.load(\"f1\", trust_remote_code = True)\n",
        "    precision_metric = evaluate.load(\"precision\", trust_remote_code = True)\n",
        "    recall_metric = evaluate.load(\"recall\", trust_remote_code = True)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=preds, references=labels, average = 'weighted')\n",
        "    precision = precision_metric.compute(predictions=preds, references=labels, average = 'weighted')\n",
        "    recall = recall_metric.compute(predictions=preds, references=labels, average = 'weighted')\n",
        "    return {**accuracy, **precision, **recall}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UpbM8kbQR7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label2id {'anger': 0, 'depression': 1, 'disgust': 2, 'fear': 3, 'guilt': 4, 'joy': 5, 'mild': 6, 'minimum': 7, 'moderate': 8, 'no': 9, 'sadness': 10, 'severe': 11, 'shame': 12, 'suicidal': 13, 'yes': 14}\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='308' max='770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [308/770 00:06 < 00:09, 46.40 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m train_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     output_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/elicer/Tiny-Mental-LLM/train_and_evaluate/results\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m     do_train \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     do_eval \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     per_device_eval_batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     model\u001b[39m=\u001b[39mnew_model,\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     args\u001b[39m=\u001b[39mtrain_args\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mpredict(test_dataset \u001b[39m=\u001b[39;49m dataset)\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m preds \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mpredictions\n\u001b[1;32m     <a href='vscode-notebook-cell://sqkhywgbasdstswq.tunnel-pt.elice.io/home/elicer/Tiny-Mental-LLM/train_and_evaluate/Evaluate.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m labels \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mlabel_ids\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:4053\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4050\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   4052\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4053\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   4054\u001b[0m     test_dataloader, description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPrediction\u001b[39;49m\u001b[39m\"\u001b[39;49m, ignore_keys\u001b[39m=\u001b[39;49mignore_keys, metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix\n\u001b[1;32m   4055\u001b[0m )\n\u001b[1;32m   4056\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   4057\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:4169\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4166\u001b[0m         batch_size \u001b[39m=\u001b[39m observed_batch_size\n\u001b[1;32m   4168\u001b[0m \u001b[39m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4169\u001b[0m losses, logits, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_step(model, inputs, prediction_loss_only, ignore_keys\u001b[39m=\u001b[39;49mignore_keys)\n\u001b[1;32m   4170\u001b[0m main_input_name \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39m\"\u001b[39m\u001b[39mmain_input_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4171\u001b[0m inputs_decode \u001b[39m=\u001b[39m (\n\u001b[1;32m   4172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m args\u001b[39m.\u001b[39minclude_for_metrics \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:4385\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4383\u001b[0m \u001b[39mif\u001b[39;00m has_labels \u001b[39mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   4384\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4385\u001b[0m         loss, outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(model, inputs, return_outputs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   4386\u001b[0m     loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m   4388\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mdict\u001b[39m):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3631\u001b[0m         loss_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_items_in_batch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3632\u001b[0m     inputs \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3633\u001b[0m outputs \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs)\n\u001b[1;32m   3634\u001b[0m \u001b[39m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m \u001b[39m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpast_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:1251\u001b[0m, in \u001b[0;36mQwen2ForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1251\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[1;32m   1252\u001b[0m     input_ids,\n\u001b[1;32m   1253\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1254\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m   1255\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1256\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m   1257\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1258\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1259\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1260\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1261\u001b[0m )\n\u001b[1;32m   1262\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1263\u001b[0m logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore(hidden_states)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:895\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    883\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    884\u001b[0m         decoder_layer\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m,\n\u001b[1;32m    885\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m         position_embeddings,\n\u001b[1;32m    893\u001b[0m     )\n\u001b[1;32m    894\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m     layer_outputs \u001b[39m=\u001b[39m decoder_layer(\n\u001b[1;32m    896\u001b[0m         hidden_states,\n\u001b[1;32m    897\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mcausal_mask,\n\u001b[1;32m    898\u001b[0m         position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    899\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    900\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    901\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    902\u001b[0m         cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    903\u001b[0m         position_embeddings\u001b[39m=\u001b[39;49mposition_embeddings,\n\u001b[1;32m    904\u001b[0m     )\n\u001b[1;32m    906\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    908\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:623\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    622\u001b[0m \u001b[39m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    624\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[1;32m    625\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    626\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[1;32m    627\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    628\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    629\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    630\u001b[0m     cache_position\u001b[39m=\u001b[39;49mcache_position,\n\u001b[1;32m    631\u001b[0m     position_embeddings\u001b[39m=\u001b[39;49mposition_embeddings,\n\u001b[1;32m    632\u001b[0m )\n\u001b[1;32m    633\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n\u001b[1;32m    635\u001b[0m \u001b[39m# Fully Connected\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:519\u001b[0m, in \u001b[0;36mQwen2SdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     cos, sin \u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m--> 519\u001b[0m query_states, key_states \u001b[39m=\u001b[39m apply_rotary_pos_emb(query_states, key_states, cos, sin)\n\u001b[1;32m    521\u001b[0m \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     cache_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msin\u001b[39m\u001b[39m\"\u001b[39m: sin, \u001b[39m\"\u001b[39m\u001b[39mcos\u001b[39m\u001b[39m\"\u001b[39m: cos, \u001b[39m\"\u001b[39m\u001b[39mcache_position\u001b[39m\u001b[39m\"\u001b[39m: cache_position}  \u001b[39m# Specific to RoPE models\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:207\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    205\u001b[0m sin \u001b[39m=\u001b[39m sin\u001b[39m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    206\u001b[0m q_embed \u001b[39m=\u001b[39m (q \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_half(q) \u001b[39m*\u001b[39m sin)\n\u001b[0;32m--> 207\u001b[0m k_embed \u001b[39m=\u001b[39m (k \u001b[39m*\u001b[39m cos) \u001b[39m+\u001b[39m (rotate_half(k) \u001b[39m*\u001b[39m sin)\n\u001b[1;32m    208\u001b[0m \u001b[39mreturn\u001b[39;00m q_embed, k_embed\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py:176\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[39mreturn\u001b[39;00m cos\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype), sin\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    175\u001b[0m \u001b[39m# Copied from transformers.models.llama.modeling_llama.rotate_half\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrotate_half\u001b[39m(x):\n\u001b[1;32m    177\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     x1 \u001b[39m=\u001b[39m x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, : x\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m]\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from evaluate import evaluator\n",
        "from evaluate import load, combine\n",
        "import evaluate\n",
        "import csv\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoConfig\n",
        "import evaluate\n",
        "\n",
        "token = \"\" #Huggingface token to access the model\n",
        "# Load model directly\n",
        "tokenizer = AutoTokenizer.from_pretrained(token_path, token = token, model_max_length = 2048, truncation_side = \"left\")\n",
        "new_model = AutoModelForSequenceClassification.from_pretrained(f\"{model_path}\") # Check the config.json for the proper name\n",
        "\n",
        "label2id = model_config.label2id\n",
        "print(\"Label2id\", label2id)\n",
        "\n",
        "new_model.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for test_dataset_name in test_dataset_names:\n",
        "    # _test_texts, _test_labels = _get_text_label_from_path(f\"{data_path}/{test_dataset_name}.csv\")\n",
        "    # _test_encodings = tokenizer(_test_texts , truncation = True)\n",
        "    # _test_dataset = CustomDataset(_test_labels, _test_encodings)\n",
        "\n",
        "    dataset = Dataset.from_csv(f\"{data_path}/{test_dataset_name}.csv\")\n",
        "    dataset = dataset.map(lambda example: {\"label\": label2id[example[\"label\"]], 'input_ids': tokenizer(example['text']).input_ids})\n",
        "\n",
        "    task_evaluator = evaluator(\"text-classification\")\n",
        "\n",
        "\n",
        "    # 1. Pass a model name or path\n",
        "    train_args = TrainingArguments(\n",
        "        output_dir = \"/home/elicer/Tiny-Mental-LLM/train_and_evaluate/results\",\n",
        "        do_train = False,\n",
        "        do_eval = True,\n",
        "        per_device_eval_batch_size = 1,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=new_model,\n",
        "        args=train_args\n",
        "    )\n",
        "\n",
        "    results = trainer.predict(test_dataset = dataset)\n",
        "    \n",
        "    preds = results.predictions\n",
        "    labels = results.label_ids\n",
        "\n",
        "    preds = torch.from_numpy(preds)\n",
        "    preds = torch.argmax(preds, dim = -1)\n",
        "    labels = torch.from_numpy(labels)\n",
        "\n",
        "    print(f\"For dataset {test_dataset_name}, the results are: {compute_metrics(preds, labels)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
